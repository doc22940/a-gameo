(window.webpackJsonp=window.webpackJsonp||[]).push([[13],{109:function(e,t,n){"use strict";n.d(t,"a",(function(){return m})),n.d(t,"b",(function(){return b}));var r=n(0),a=n.n(r);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},i=Object.keys(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var c=a.a.createContext({}),d=function(e){var t=a.a.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},m=function(e){var t=d(e.components);return a.a.createElement(c.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return a.a.createElement(a.a.Fragment,{},t)}},u=a.a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,i=e.originalType,o=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),m=d(n),u=r,b=m["".concat(o,".").concat(u)]||m[u]||p[u]||i;return n?a.a.createElement(b,s(s({ref:t},c),{},{components:n})):a.a.createElement(b,s({ref:t},c))}));function b(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=n.length,o=new Array(i);o[0]=u;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:r,o[1]=s;for(var c=2;c<i;c++)o[c]=n[c];return a.a.createElement.apply(null,o)}return a.a.createElement.apply(null,n)}u.displayName="MDXCreateElement"},67:function(e,t,n){"use strict";n.r(t),n.d(t,"frontMatter",(function(){return o})),n.d(t,"metadata",(function(){return s})),n.d(t,"rightToc",(function(){return l})),n.d(t,"default",(function(){return d}));var r=n(2),a=n(6),i=(n(0),n(109)),o={id:"training",title:"Implementing the Model",slug:"/implementing-the-model"},s={unversionedId:"training",id:"version-en/training",isDocsHomePage:!1,title:"Implementing the Model",description:"Before following the tutorial, you should have:",source:"@site/versioned_docs\\version-en\\training.md",slug:"/implementing-the-model",permalink:"/Gameo/docs/implementing-the-model",editUrl:"https://github.com/facebook/docusaurus/edit/master/website/versioned_docs/version-en/training.md",version:"en",sidebar:"version-en/docs",previous:{title:"Preparing Dataset for PyTorch",permalink:"/Gameo/docs/preparing-dataset-for-pytorch"},next:{title:"Overview",permalink:"/Gameo/docs/overview"}},l=[{value:"Matrix Factorization Model in PyTorch",id:"matrix-factorization-model-in-pytorch",children:[]},{value:"Model Prediction",id:"model-prediction",children:[]}],c={rightToc:l};function d(e){var t=e.components,n=Object(a.a)(e,["components"]);return Object(i.b)("wrapper",Object(r.a)({},c,n,{components:t,mdxType:"MDXLayout"}),Object(i.b)("div",{className:"admonition admonition-important alert alert--info"},Object(i.b)("div",Object(r.a)({parentName:"div"},{className:"admonition-heading"}),Object(i.b)("h5",{parentName:"div"},Object(i.b)("span",Object(r.a)({parentName:"h5"},{className:"admonition-icon"}),Object(i.b)("svg",Object(r.a)({parentName:"span"},{xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"}),Object(i.b)("path",Object(r.a)({parentName:"svg"},{fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"})))),"important")),Object(i.b)("div",Object(r.a)({parentName:"div"},{className:"admonition-content"}),Object(i.b)("p",{parentName:"div"},"Before following the tutorial, you should have:"),Object(i.b)("ul",{parentName:"div"},Object(i.b)("li",{parentName:"ul"},"PyTorch installed in your machine. Read instructions ",Object(i.b)("a",Object(r.a)({parentName:"li"},{href:"https://pytorch.org/get-started/locally/"}),"here"),"."),Object(i.b)("li",{parentName:"ul"},"CSV file with dataset from ",Object(i.b)("a",Object(r.a)({parentName:"li"},{href:"/Gameo/docs/preparing-dataset-for-pytorch"}),"Preparing Dataset for PyTorch"),".")))),Object(i.b)("h2",{id:"matrix-factorization-model-in-pytorch"},"Matrix Factorization Model in PyTorch"),Object(i.b)("p",null,"Taking the idea of Matrix Factorization, let's implement this in PyTorch."),Object(i.b)("p",null,"First, let's import some necessary modules."),Object(i.b)("pre",null,Object(i.b)("code",Object(r.a)({parentName:"pre"},{}),"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom sklearn.model_selection import train_test_split\n")),Object(i.b)("p",null,"Next, let's build our Matrix Factorization Model class."),Object(i.b)("pre",null,Object(i.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"class MF(nn.Module):\n    def __init__(self, num_users, num_items, emb_size=100):\n        super(MF, self).__init__()\n        self.user_emb = nn.Embedding(num_users, emb_size)\n        self.item_emb = nn.Embedding(num_items, emb_size)\n\n        # initializing our matrices with a positive number generally will yield better results\n        self.user_emb.weight.data.uniform_(0, 0.5)\n        self.item_emb.weight.data.uniform_(0, 0.5)\n        \n    def forward(self, u, v):\n        u = self.user_emb(u)\n        v = self.item_emb(v)\n        return (u*v).sum(1)  # taking the dot product\n")),Object(i.b)("p",null,"To instantiate our model, we can simply call on it like so:"),Object(i.b)("div",{className:"admonition admonition-note alert alert--secondary"},Object(i.b)("div",Object(r.a)({parentName:"div"},{className:"admonition-heading"}),Object(i.b)("h5",{parentName:"div"},Object(i.b)("span",Object(r.a)({parentName:"h5"},{className:"admonition-icon"}),Object(i.b)("svg",Object(r.a)({parentName:"span"},{xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"}),Object(i.b)("path",Object(r.a)({parentName:"svg"},{fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"})))),"note")),Object(i.b)("div",Object(r.a)({parentName:"div"},{className:"admonition-content"}),Object(i.b)("p",{parentName:"div"},"The variables ",Object(i.b)("strong",{parentName:"p"},"num_users")," and ",Object(i.b)("strong",{parentName:"p"},"num_items")," represent the number of unique users and unique items in the dataset respectively."))),Object(i.b)("pre",null,Object(i.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"model = MF(num_users, num_items, emb_size=100)\n")),Object(i.b)("p",null,"Currently, this is what the dataset looks like:"),Object(i.b)("p",null,Object(i.b)("img",Object(r.a)({parentName:"p"},{src:"https://cdn.hashnode.com/res/hashnode/image/upload/v1602020247881/bfBpkQD4Z.png",alt:"dataset.PNG"}))),Object(i.b)("p",null,"The items here are games that we want to recommend to users."),Object(i.b)("p",null,"Once the model is instantiated, we can proceed to split our dataset to train and test our model. The general split is 20% test and 80% training."),Object(i.b)("pre",null,Object(i.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"train_df, valid_df = train_test_split(dataset, test_size=0.2)\n\n# resetting indices to avoid indexing errors\ntrain_df = train_df.reset_index(drop=True)\ntest_df = valid_df.reset_index(drop=True)\n")),Object(i.b)("p",null,"Now, we want to create our training function to train the model."),Object(i.b)("pre",null,Object(i.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"def train_epocs(model, epochs=10, lr=0.01, wd=0.0):\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n    model.train()\n    for i in range(epochs):\n        usernames = torch.LongTensor(train_df.UserId.values)\n        game_titles = torch.LongTensor(train_df.TitleId.values)\n        ratings = torch.FloatTensor(train_df.Userscore.values)\n        y_hat = model(usernames, game_titles)\n        loss = F.mse_loss(y_hat, ratings)\n        optimizer.zero_grad()  # reset gradient\n        loss.backward()\n        optimizer.step()\n        print(loss.item())\n    test(model)\n")),Object(i.b)("p",null,"In each iteration, the training function is  updating our model to approach a smaller MSE (mean squared error). This is the idea of gradient descent. "),Object(i.b)("p",null,"And finally, we want to create our test function, which will be called right after training is done."),Object(i.b)("pre",null,Object(i.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),'def test(model):\n    model.eval()\n    usernames = torch.LongTensor(test_df.UserId.values)\n    game_titles = torch.LongTensor(test_df.TitleId.values)\n    ratings = torch.FloatTensor(test_df.Userscore.values)\n    y_hat = model(usernames, game_titles)\n    loss = F.mse_loss(y_hat, ratings)\n    print("test loss %.3f " % loss.item())\n')),Object(i.b)("p",null,"We can see that although our model's lowest MSE in our training dataset was about 3.776, the actual MSE based on our test dataset is about 8.778. Generally, this is a normal result, but a big difference between the training and test MSE likely suggests that our model is overfitted."),Object(i.b)("p",null,Object(i.b)("img",Object(r.a)({parentName:"p"},{src:"https://cdn.hashnode.com/res/hashnode/image/upload/v1602021212841/Qy7kiRGDS.png",alt:"result.PNG"}))),Object(i.b)("h2",{id:"model-prediction"},"Model Prediction"),Object(i.b)("p",null,"And now, we are ready to use our model for prediction! For example, to predict the ratings of games for user of user id 10, we can run the following lines:"),Object(i.b)("pre",null,Object(i.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"user = torch.tensor([10])\ngames = torch.tensor(game_ratings['TitleId'].unique().tolist())\npredictions = model(user, games).tolist()\nprint(predictions)\n")),Object(i.b)("p",null,"Notice that some of the predictions went over 10. To fix this, we can simply normalize our results like so:"),Object(i.b)("pre",null,Object(i.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"normalized_predictions = [i/max(predictions)*10 for i in predictions]\nprint(normalized_predictions)\n")),Object(i.b)("p",null," Finally, we can recommend some games by sorting our predictions list:"),Object(i.b)("pre",null,Object(i.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"sortedIndices = predictions.argsort()\nrecommendations = dataset['Title'].unique()[sortedIndices][:30]  # taking top 30 games\nprint(recommendations)\n")))}d.isMDXComponent=!0}}]);